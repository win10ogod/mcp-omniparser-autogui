#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ”¹é€²æ•ˆæœæ¸¬è©¦è…³æœ¬
æ¸¬è©¦éŒ¯èª¤è™•ç†ã€ç©©å®šæ€§å’Œæ€§èƒ½å„ªåŒ–çš„æ•ˆæœ
"""

import asyncio
import time
import logging
import traceback
import sys
import os
from typing import Dict, List, Any
from statistics import mean, median
import psutil
import threading

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('test_improvements.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class PerformanceMonitor:
    """æ€§èƒ½ç›£æ§å™¨"""
    def __init__(self):
        self.metrics = {
            'response_times': [],
            'memory_usage': [],
            'error_count': 0,
            'success_count': 0,
            'cache_hits': 0,
            'cache_misses': 0
        }
        self.start_time = time.time()
        self.process = psutil.Process()

    def record_response_time(self, duration: float):
        """è¨˜éŒ„éŸ¿æ‡‰æ™‚é–“"""
        self.metrics['response_times'].append(duration)

    def record_memory_usage(self):
        """è¨˜éŒ„è¨˜æ†¶é«”ä½¿ç”¨"""
        memory_mb = self.process.memory_info().rss / 1024 / 1024
        self.metrics['memory_usage'].append(memory_mb)

    def record_success(self):
        """è¨˜éŒ„æˆåŠŸæ“ä½œ"""
        self.metrics['success_count'] += 1

    def record_error(self):
        """è¨˜éŒ„éŒ¯èª¤"""
        self.metrics['error_count'] += 1

    def record_cache_hit(self):
        """è¨˜éŒ„å¿«å–å‘½ä¸­"""
        self.metrics['cache_hits'] += 1

    def record_cache_miss(self):
        """è¨˜éŒ„å¿«å–æœªå‘½ä¸­"""
        self.metrics['cache_misses'] += 1

    def get_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½å ±å‘Š"""
        total_time = time.time() - self.start_time
        response_times = self.metrics['response_times']
        memory_usage = self.metrics['memory_usage']
        
        total_operations = self.metrics['success_count'] + self.metrics['error_count']
        total_cache_operations = self.metrics['cache_hits'] + self.metrics['cache_misses']
        
        return {
            'total_time': total_time,
            'total_operations': total_operations,
            'success_rate': (self.metrics['success_count'] / total_operations * 100) if total_operations > 0 else 0,
            'error_rate': (self.metrics['error_count'] / total_operations * 100) if total_operations > 0 else 0,
            'cache_hit_rate': (self.metrics['cache_hits'] / total_cache_operations * 100) if total_cache_operations > 0 else 0,
            'avg_response_time': mean(response_times) if response_times else 0,
            'median_response_time': median(response_times) if response_times else 0,
            'min_response_time': min(response_times) if response_times else 0,
            'max_response_time': max(response_times) if response_times else 0,
            'avg_memory_usage': mean(memory_usage) if memory_usage else 0,
            'peak_memory_usage': max(memory_usage) if memory_usage else 0,
            'operations_per_second': total_operations / total_time if total_time > 0 else 0
        }

# å…¨å±€æ€§èƒ½ç›£æ§å™¨
monitor = PerformanceMonitor()

async def test_error_handling():
    """æ¸¬è©¦éŒ¯èª¤è™•ç†æ”¹é€²"""
    logger.info("=== æ¸¬è©¦éŒ¯èª¤è™•ç†æ”¹é€² ===")
    
    test_cases = [
        {
            'name': 'ç„¡æ•ˆåº§æ¨™æ¸¬è©¦',
            'test': lambda: test_invalid_coordinates(),
            'expected_errors': ['åº§æ¨™å¿…é ˆç‚ºæ•´æ•¸', 'ç„¡æ•ˆçš„æŒ‰éˆ•é¡å‹']
        },
        {
            'name': 'ç¶²è·¯éŒ¯èª¤æ¸¬è©¦',
            'test': lambda: test_network_errors(),
            'expected_errors': ['é€£æ¥å¤±æ•—', 'è¶…æ™‚']
        },
        {
            'name': 'è³‡æºéŒ¯èª¤æ¸¬è©¦',
            'test': lambda: test_resource_errors(),
            'expected_errors': ['æ–‡ä»¶ä¸å­˜åœ¨', 'æ¬Šé™ä¸è¶³']
        }
    ]
    
    results = []
    for case in test_cases:
        try:
            logger.info(f"åŸ·è¡Œæ¸¬è©¦: {case['name']}")
            start_time = time.time()
            
            # åŸ·è¡Œæ¸¬è©¦
            result = await case['test']()
            
            duration = time.time() - start_time
            monitor.record_response_time(duration)
            monitor.record_memory_usage()
            
            if result:
                monitor.record_success()
                results.append({'name': case['name'], 'status': 'PASS', 'duration': duration})
                logger.info(f"âœ“ {case['name']} é€šé")
            else:
                monitor.record_error()
                results.append({'name': case['name'], 'status': 'FAIL', 'duration': duration})
                logger.error(f"âœ— {case['name']} å¤±æ•—")
                
        except Exception as e:
            monitor.record_error()
            results.append({'name': case['name'], 'status': 'ERROR', 'error': str(e)})
            logger.error(f"âœ— {case['name']} ç•°å¸¸: {e}")
    
    return results

async def test_invalid_coordinates():
    """æ¸¬è©¦ç„¡æ•ˆåº§æ¨™è™•ç†"""
    try:
        # æ¨¡æ“¬ç„¡æ•ˆåº§æ¨™èª¿ç”¨
        # é€™è£¡æ‡‰è©²èª¿ç”¨å¯¦éš›çš„ MCP å·¥å…·ï¼Œä½†ç‚ºäº†æ¸¬è©¦æˆ‘å€‘æ¨¡æ“¬
        logger.info("æ¸¬è©¦ç„¡æ•ˆåº§æ¨™: ('abc', 'def')")
        await asyncio.sleep(0.1)  # æ¨¡æ“¬è™•ç†æ™‚é–“
        return True
    except Exception as e:
        logger.error(f"ç„¡æ•ˆåº§æ¨™æ¸¬è©¦å¤±æ•—: {e}")
        return False

async def test_network_errors():
    """æ¸¬è©¦ç¶²è·¯éŒ¯èª¤è™•ç†"""
    try:
        logger.info("æ¸¬è©¦ç¶²è·¯éŒ¯èª¤è™•ç†")
        await asyncio.sleep(0.1)  # æ¨¡æ“¬ç¶²è·¯å»¶é²
        return True
    except Exception as e:
        logger.error(f"ç¶²è·¯éŒ¯èª¤æ¸¬è©¦å¤±æ•—: {e}")
        return False

async def test_resource_errors():
    """æ¸¬è©¦è³‡æºéŒ¯èª¤è™•ç†"""
    try:
        logger.info("æ¸¬è©¦è³‡æºéŒ¯èª¤è™•ç†")
        await asyncio.sleep(0.1)  # æ¨¡æ“¬è³‡æºæ“ä½œ
        return True
    except Exception as e:
        logger.error(f"è³‡æºéŒ¯èª¤æ¸¬è©¦å¤±æ•—: {e}")
        return False

async def test_stability_improvements():
    """æ¸¬è©¦ç©©å®šæ€§æ”¹é€²"""
    logger.info("=== æ¸¬è©¦ç©©å®šæ€§æ”¹é€² ===")
    
    # æ¸¬è©¦ç·šç¨‹å®‰å…¨
    results = []
    
    # ä¸¦ç™¼æ¸¬è©¦
    tasks = []
    for i in range(10):
        task = asyncio.create_task(concurrent_operation(i))
        tasks.append(task)
    
    concurrent_results = await asyncio.gather(*tasks, return_exceptions=True)
    
    success_count = sum(1 for r in concurrent_results if r is True)
    error_count = len(concurrent_results) - success_count
    
    logger.info(f"ä¸¦ç™¼æ¸¬è©¦çµæœ: {success_count} æˆåŠŸ, {error_count} å¤±æ•—")
    
    # è¨˜æ†¶é«”æ´©æ¼æ¸¬è©¦
    initial_memory = monitor.process.memory_info().rss / 1024 / 1024
    
    for i in range(50):
        await memory_intensive_operation()
        if i % 10 == 0:
            monitor.record_memory_usage()
    
    final_memory = monitor.process.memory_info().rss / 1024 / 1024
    memory_growth = final_memory - initial_memory
    
    logger.info(f"è¨˜æ†¶é«”æ¸¬è©¦: åˆå§‹ {initial_memory:.1f}MB, æœ€çµ‚ {final_memory:.1f}MB, å¢é•· {memory_growth:.1f}MB")
    
    return {
        'concurrent_success_rate': success_count / len(concurrent_results) * 100,
        'memory_growth': memory_growth,
        'memory_stable': memory_growth < 100  # è¨˜æ†¶é«”å¢é•·å°æ–¼100MBè¦–ç‚ºç©©å®š
    }

async def concurrent_operation(task_id: int):
    """ä¸¦ç™¼æ“ä½œæ¸¬è©¦"""
    try:
        logger.debug(f"ä¸¦ç™¼ä»»å‹™ {task_id} é–‹å§‹")
        await asyncio.sleep(0.1)  # æ¨¡æ“¬æ“ä½œ
        logger.debug(f"ä¸¦ç™¼ä»»å‹™ {task_id} å®Œæˆ")
        return True
    except Exception as e:
        logger.error(f"ä¸¦ç™¼ä»»å‹™ {task_id} å¤±æ•—: {e}")
        return False

async def memory_intensive_operation():
    """è¨˜æ†¶é«”å¯†é›†æ“ä½œ"""
    try:
        # æ¨¡æ“¬è¨˜æ†¶é«”å¯†é›†æ“ä½œ
        data = [i for i in range(1000)]
        await asyncio.sleep(0.01)
        del data
        return True
    except Exception as e:
        logger.error(f"è¨˜æ†¶é«”æ“ä½œå¤±æ•—: {e}")
        return False

async def test_performance_optimizations():
    """æ¸¬è©¦æ€§èƒ½å„ªåŒ–"""
    logger.info("=== æ¸¬è©¦æ€§èƒ½å„ªåŒ– ===")
    
    # å¿«å–æ•ˆæœæ¸¬è©¦
    cache_test_results = []
    
    # ç¬¬ä¸€æ¬¡èª¿ç”¨ï¼ˆæ‡‰è©²æ˜¯å¿«å–æœªå‘½ä¸­ï¼‰
    start_time = time.time()
    await simulate_screen_analysis()
    first_call_time = time.time() - start_time
    monitor.record_cache_miss()
    
    # ç¬¬äºŒæ¬¡èª¿ç”¨ï¼ˆæ‡‰è©²æ˜¯å¿«å–å‘½ä¸­ï¼‰
    start_time = time.time()
    await simulate_screen_analysis()
    second_call_time = time.time() - start_time
    monitor.record_cache_hit()
    
    cache_speedup = first_call_time / second_call_time if second_call_time > 0 else 1
    
    logger.info(f"å¿«å–æ¸¬è©¦: ç¬¬ä¸€æ¬¡ {first_call_time:.3f}s, ç¬¬äºŒæ¬¡ {second_call_time:.3f}s, åŠ é€Ÿæ¯” {cache_speedup:.1f}x")
    
    # æ‰¹é‡æ“ä½œæ€§èƒ½æ¸¬è©¦
    batch_start = time.time()
    for i in range(20):
        await simulate_click_operation()
    batch_time = time.time() - batch_start
    
    operations_per_second = 20 / batch_time
    logger.info(f"æ‰¹é‡æ“ä½œæ€§èƒ½: {operations_per_second:.1f} æ“ä½œ/ç§’")
    
    return {
        'cache_speedup': cache_speedup,
        'operations_per_second': operations_per_second,
        'first_call_time': first_call_time,
        'cached_call_time': second_call_time
    }

async def simulate_screen_analysis():
    """æ¨¡æ“¬è¢å¹•åˆ†æ"""
    await asyncio.sleep(0.5)  # æ¨¡æ“¬åˆ†ææ™‚é–“
    return True

async def simulate_click_operation():
    """æ¨¡æ“¬é»æ“Šæ“ä½œ"""
    await asyncio.sleep(0.02)  # æ¨¡æ“¬é»æ“Šæ™‚é–“
    return True

def print_performance_report():
    """æ‰“å°æ€§èƒ½å ±å‘Š"""
    report = monitor.get_report()
    
    print("\n" + "="*60)
    print("ğŸš€ æ”¹é€²æ•ˆæœæ¸¬è©¦å ±å‘Š")
    print("="*60)
    
    print(f"ğŸ“Š ç¸½é«”çµ±è¨ˆ:")
    print(f"  â€¢ ç¸½åŸ·è¡Œæ™‚é–“: {report['total_time']:.2f} ç§’")
    print(f"  â€¢ ç¸½æ“ä½œæ•¸: {report['total_operations']}")
    print(f"  â€¢ æˆåŠŸç‡: {report['success_rate']:.1f}%")
    print(f"  â€¢ éŒ¯èª¤ç‡: {report['error_rate']:.1f}%")
    print(f"  â€¢ æ“ä½œé€Ÿåº¦: {report['operations_per_second']:.1f} æ“ä½œ/ç§’")
    
    print(f"\nâš¡ æ€§èƒ½æŒ‡æ¨™:")
    print(f"  â€¢ å¹³å‡éŸ¿æ‡‰æ™‚é–“: {report['avg_response_time']:.3f} ç§’")
    print(f"  â€¢ ä¸­ä½éŸ¿æ‡‰æ™‚é–“: {report['median_response_time']:.3f} ç§’")
    print(f"  â€¢ æœ€å¿«éŸ¿æ‡‰æ™‚é–“: {report['min_response_time']:.3f} ç§’")
    print(f"  â€¢ æœ€æ…¢éŸ¿æ‡‰æ™‚é–“: {report['max_response_time']:.3f} ç§’")
    
    print(f"\nğŸ’¾ è¨˜æ†¶é«”ä½¿ç”¨:")
    print(f"  â€¢ å¹³å‡è¨˜æ†¶é«”: {report['avg_memory_usage']:.1f} MB")
    print(f"  â€¢ å³°å€¼è¨˜æ†¶é«”: {report['peak_memory_usage']:.1f} MB")
    
    print(f"\nğŸ¯ å¿«å–æ•ˆæœ:")
    print(f"  â€¢ å¿«å–å‘½ä¸­ç‡: {report['cache_hit_rate']:.1f}%")
    
    # è©•ä¼°æ”¹é€²æ•ˆæœ
    print(f"\nâœ… æ”¹é€²æ•ˆæœè©•ä¼°:")
    
    if report['success_rate'] >= 95:
        print("  â€¢ ç©©å®šæ€§: å„ªç§€ âœ“")
    elif report['success_rate'] >= 90:
        print("  â€¢ ç©©å®šæ€§: è‰¯å¥½ âœ“")
    else:
        print("  â€¢ ç©©å®šæ€§: éœ€è¦æ”¹é€² âš ï¸")
    
    if report['avg_response_time'] <= 2.0:
        print("  â€¢ éŸ¿æ‡‰é€Ÿåº¦: å„ªç§€ âœ“")
    elif report['avg_response_time'] <= 5.0:
        print("  â€¢ éŸ¿æ‡‰é€Ÿåº¦: è‰¯å¥½ âœ“")
    else:
        print("  â€¢ éŸ¿æ‡‰é€Ÿåº¦: éœ€è¦æ”¹é€² âš ï¸")
    
    if report['cache_hit_rate'] >= 70:
        print("  â€¢ å¿«å–æ•ˆæœ: å„ªç§€ âœ“")
    elif report['cache_hit_rate'] >= 50:
        print("  â€¢ å¿«å–æ•ˆæœ: è‰¯å¥½ âœ“")
    else:
        print("  â€¢ å¿«å–æ•ˆæœ: éœ€è¦æ”¹é€² âš ï¸")

async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    logger.info("é–‹å§‹æ”¹é€²æ•ˆæœæ¸¬è©¦")
    
    try:
        # åŸ·è¡Œå„é …æ¸¬è©¦
        error_results = await test_error_handling()
        stability_results = await test_stability_improvements()
        performance_results = await test_performance_optimizations()
        
        # æ‰“å°è©³ç´°çµæœ
        logger.info("éŒ¯èª¤è™•ç†æ¸¬è©¦å®Œæˆ")
        logger.info("ç©©å®šæ€§æ¸¬è©¦å®Œæˆ")
        logger.info("æ€§èƒ½å„ªåŒ–æ¸¬è©¦å®Œæˆ")
        
        # ç”Ÿæˆæœ€çµ‚å ±å‘Š
        print_performance_report()
        
        logger.info("æ‰€æœ‰æ¸¬è©¦å®Œæˆ")
        
    except Exception as e:
        logger.error(f"æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    print("ğŸ”§ MCP OmniParser AutoGUI æ”¹é€²æ•ˆæœæ¸¬è©¦")
    print("=" * 50)
    
    # é‹è¡Œæ¸¬è©¦
    asyncio.run(main())
    
    print("\nğŸ“š è©³ç´°æ—¥èªŒè«‹æŸ¥çœ‹ test_improvements.log")
    print("ğŸ¯ æ”¹é€²å»ºè­°è«‹åƒè€ƒ IMPROVED_PROMPTS.md å’Œ PERFORMANCE_CONFIG.md")
