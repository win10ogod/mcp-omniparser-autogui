[project]
name = "mcp-omniparser-autogui"
version = "0.1.0"
description = "Automatic operation of on-screen GUI."
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "accelerate>=1.4.0",
    "anthropic[bedrock,vertex]>=0.37.1",
    "azure-identity>=1.20.0",
    "boto3>=1.28.57",
    "dashscope>=1.22.1",
    "dill>=0.3.9",
    "easyocr>=1.7.2",
    "einops==0.8.0",
    "google-auth>=2,<3",
    "gradio>=5.13.2",
    "groq>=0.18.0",
    "jsonschema==4.22.0",
    "numpy==1.26.4",
    "openai>=1.58.1",
    "opencv-python>=4.11.0.86",
    "opencv-python-headless>=4.11.0.86",
    "paddleocr>=2.9.1",
    "paddlepaddle>=2.6.2",
    "pre-commit==3.8.0",
    "pyautogui==0.9.54",
    "pytest==8.3.3",
    "pytest-asyncio==0.23.6",
    "ruff==0.6.7",
    "screeninfo>=0.8.1",
    "streamlit>=1.38.0",
    "supervision==0.18.0",
    "timm>=1.0.14",
    "torch>=2.6.0",
    "torchvision>=0.21.0",
    "transformers>=4.49.0",
    "uiautomation>=2.0.20",
    "ultralytics==8.3.70",
    "uvicorn>=0.34.0",
    "pandas>=2.2.3",
    "setuptools>=75.6.0",
    "pyperclip>=1.9.0",
    "mcp[cli]>=1.3.0",
    "requests>=2.32.3",
]
license = {text = "MIT License"}
license-files = ["LICENSE"]

[project.scripts]
mcp-omniparser-autogui = "mcp_autogui:main"
omniparserserver = "omniparserserver:main"

[tool.hatch.build.targets.wheel]
packages = [
  "src/mcp_autogui",
  "src/omniparserserver"
]

[project.optional-dependencies]
langchain = [
    "langchain-mcp",
    "langchain",
    "langchain-community",
    "langchain-google-genai",
    "langchain-openai>=0.3.6",
    "langgraph",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.uv.sources]
torch = [
  { index = "pytorch-cu118", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
]
torchvision = [
  { index = "pytorch-cu118", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
]
langchain-mcp = { git = "https://github.com/NON906/langchain-mcp.git", branch = "main" }

[[tool.uv.index]]
name = "pytorch-cu118"
url = "https://download.pytorch.org/whl/cu118"
explicit = true
